import os
import re
import time
import uuid
import warnings
warnings.filterwarnings('ignore')

from dotenv import load_dotenv

# Selenium ê´€ë ¨
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from selenium.webdriver.chrome.options import Options

import pandas as pd
import pymysql
import urllib.parse
from sqlalchemy import create_engine




def get_hotel_link(conn, ota):
    """
    í˜¸í…” ì •ë³´ í…Œì´ë¸”(hotels)ì™€ í˜¸í…”ë³„ OTA ë§í¬(hotel-otas) í…Œì´ë¸”ì„ ì¡°ì¸í•˜ì—¬
    íŠ¹ì • OTAì— ëŒ€í•œ hotel_id, í˜¸í…”ëª…, ì£¼ì†Œ, ë§í¬ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    sql = f"""
    SELECT 
       h.id AS hotel_id,
       h.name AS hotel_name,
       h.address,
       urls.ota,
       urls.link
    FROM hotels AS h
    INNER JOIN `hotel-otas` AS urls ON h.id = urls.hotelId
    WHERE urls.ota = '{ota}';
    """
    df = pd.read_sql(sql, conn)
    return df


def get_latest_review_ikyu(df, conn):
    """
    ì£¼ì–´ì§„ DataFrame(df) ë‚´ hotel_id ëª©ë¡ì„ ê¸°ì¤€ìœ¼ë¡œ,
    ê° í˜¸í…”(IKYU)ì—ì„œ ê°€ìž¥ ìµœì‹ ì— ì €ìž¥ëœ ë¦¬ë·°(1ê±´)ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    """
    hotel_ids = df['hotel_id'].unique()
    hotel_ids_str = ",".join(map(str, hotel_ids))
    
    sql = f"""
    SELECT *
    FROM (
      SELECT 
        hr.id, 
        hr.hotelId, 
        hr.authorName, 
        hr.content, 
        hr.reviewCreatedAt, 
        hr.ota,
        ROW_NUMBER() OVER (PARTITION BY hr.hotelId ORDER BY hr.reviewCreatedAt DESC) AS rn
      FROM `hotel-reviews` AS hr
      WHERE hr.ota = 'IKYU' 
        AND hr.hotelId IN ({hotel_ids_str})
    ) AS sub
    WHERE rn = 1
    ORDER BY hotelId, reviewCreatedAt DESC;
    """
    latest_reviews_df = pd.read_sql(sql, conn)
    return latest_reviews_df


def count_reviews_ikyu_split(df, conn):
    """
    ì£¼ì–´ì§„ ë°ì´í„°í”„ë ˆìž„(df)ì—ì„œ 'hotel_id' ì»¬ëŸ¼ì„ ê¸°ì¤€ìœ¼ë¡œ,
    'IKYU' OTAì˜ ì „ì²´ ë¦¬ë·°ìˆ˜ë¥¼ ì¡°íšŒí•˜ì—¬, 
    ì›ë³¸ì˜ ëª¨ë“  í˜¸í…” ì •ë³´ë¥¼ ìœ ì§€í•œ ì±„ review_count ì¹¼ëŸ¼ì„ ì¶”ê°€í•˜ê³ ,
    ë¦¬ë·°ê°€ ì „í˜€ ì—†ëŠ” í˜¸í…”(new_hotel_list)ê³¼ ë¦¬ë·°ê°€ 1ê°œ ì´ìƒ ìžˆëŠ” í˜¸í…”(exisin_hotel_list)ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    
    Parameters:
        df: ë¦¬ë·° í¬ë¡¤ë§ ëŒ€ìƒ í˜¸í…” ì •ë³´ê°€ ë‹´ê¸´ DataFrame (ë°˜ë“œì‹œ 'hotel_id' ì»¬ëŸ¼ í¬í•¨, ê·¸ ì™¸ ì¶”ê°€ ì •ë³´ í¬í•¨)
        conn: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
        
    Returns:
        new_hotel_list: ë¦¬ë·°ê°€ 0ê°œì¸ í˜¸í…”ë“¤ì˜ DataFrame (ì›ë³¸ì˜ ëª¨ë“  ì»¬ëŸ¼ + review_count)
        exisin_hotel_list: ë¦¬ë·°ê°€ 1ê°œ ì´ìƒì¸ í˜¸í…”ë“¤ì˜ DataFrame (ì›ë³¸ì˜ ëª¨ë“  ì»¬ëŸ¼ + review_count)
    """
    # ì›ë³¸ dfì˜ í˜¸í…” ì •ë³´(ì¤‘ë³µ ì œê±°: hotel_id ê¸°ì¤€)
    hotel_info = df.drop_duplicates(subset=['hotel_id'])
    hotel_ids = hotel_info['hotel_id'].unique()
    hotel_ids_str = ",".join(map(str, hotel_ids))
    
    # IKYU ë¦¬ë·°ì— ëŒ€í•´ í˜¸í…”ë³„ ë¦¬ë·° ê°œìˆ˜ë¥¼ ì„¸ëŠ” SQL ì¿¼ë¦¬
    sql = f"""
    SELECT hr.hotelId AS hotel_id, COUNT(*) AS review_count
    FROM `hotel-reviews` AS hr
    WHERE hr.ota = 'IKYU' AND hr.hotelId IN ({hotel_ids_str})
    GROUP BY hr.hotelId;
    """
    
    # ì¿¼ë¦¬ ì‹¤í–‰: ë¦¬ë·°ê°€ ìžˆëŠ” í˜¸í…”ì— ëŒ€í•´ì„œë§Œ ê²°ê³¼ê°€ ë°˜í™˜ë¨
    count_df = pd.read_sql(sql, conn)
    
    # ì›ë³¸ í˜¸í…” ì •ë³´ì™€ ë¦¬ë·° ê°œìˆ˜ë¥¼ ë³‘í•© (ë¦¬ë·° ì—†ëŠ” í˜¸í…”ë„ í¬í•¨)
    merged_df = hotel_info.merge(count_df, on='hotel_id', how='left')
    merged_df['review_count'] = merged_df['review_count'].fillna(0).astype(int)
    
    # ë¦¬ë·° ìˆ˜ì— ë”°ë¼ ë¶„ë¦¬
    new_hotel_list = merged_df[merged_df['review_count'] == 0]
    exisin_hotel_list = merged_df[merged_df['review_count'] > 0]
    
    return new_hotel_list, exisin_hotel_list




def crawl_reviews_ikyu_fresh_new(df):
    """
    ì²˜ìŒìœ¼ë¡œ IKYU ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•˜ëŠ” í˜¸í…”ë“¤(ì´ì „ ë¦¬ë·° 0ê°œ ëŒ€ìƒ)ì— ëŒ€í•œ í’€ í¬ë¡¤ë§ í•¨ìˆ˜
    """
    review_list = []
    total_hotels = len(df)
    print(f"ðŸ” ì´ {total_hotels}ê°œì˜ [ì‹ ê·œ í˜¸í…”]ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.")

    chrome_options = Options()
    chrome_options.add_experimental_option("detach", True)
    driver = webdriver.Chrome(options=chrome_options)
    time.sleep(3)

    for idx, row in df.iterrows():
        time.sleep(3)
        hotel_link = row['link']
        print(f"\nðŸš€ [{idx+1}/{total_hotels}] í˜¸í…” í¬ë¡¤ë§ ì‹œìž‘: {hotel_link}")

        try:
            driver.get(hotel_link)
            driver.set_window_position(0, 0)
            driver.execute_script("window.scrollTo(0, 500);")

            # ë¦¬ë·° ë²„íŠ¼ í´ë¦­
            try:
                element = WebDriverWait(driver, 5).until(
                    EC.element_to_be_clickable((By.XPATH, "//span[contains(@class, 'text-sm') and contains(@class, 'font-normal') and contains(@class, 'text-blue-700')]"))
                )
            except (NoSuchElementException, TimeoutException):
                try:
                    element = WebDriverWait(driver, 5).until(
                        EC.element_to_be_clickable((By.XPATH, "//button[contains(., 'ã‚¯ãƒã‚³ãƒŸã‚’ã™ã¹ã¦ã¿ã‚‹')]"))
                    )
                except (NoSuchElementException, TimeoutException):
                    print("âŒ ë¦¬ë·° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ í˜¸í…”ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
                    continue

            driver.execute_script("arguments[0].click();", element)

            # ë¦¬ë·° ëª©ë¡ ë¡œë“œ ëŒ€ê¸°
            try:
                parent_element = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CLASS_NAME, "bg-gray-100.px-10.py-16"))
                )
                print(f"âœ… [{idx+1}] ë¦¬ë·° ëª©ë¡ ë¡œë“œë¨!")
            except Exception:
                print(f"âš ï¸ [{idx+1}] ë¦¬ë·° ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ!")
                continue

            # "ç¶šãã‚’ã¿ã‚‹" ë¬´í•œ ìŠ¤í¬ë¡¤(ë˜ëŠ” ë‹¤ë‹¨ ë¡œë”©) ì²˜ë¦¬
            while True:
                try:
                    next_button = driver.find_element(By.XPATH, "//button[contains(., 'ç¶šãã‚’ã¿ã‚‹')]")
                    if next_button.is_displayed() and next_button.is_enabled():
                        next_button.click()
                        time.sleep(2)  # ë¡œë”© ëŒ€ê¸°
                    else:
                        break
                except Exception:
                    break

            # ë¦¬ë·° ì¶”ì¶œ
            review_elements = parent_element.find_elements(By.XPATH, ".//li[section[@itemprop='reviewRating']]")
            print(f"ðŸ“Œ [{idx+1}] ì´ {len(review_elements)}ê°œì˜ ë¦¬ë·°ë¥¼ ì°¾ìŒ!")

            for review_index, review in enumerate(review_elements, start=1):
                try:
                    rating = review.find_element(By.XPATH, ".//span[@itemprop='ratingValue']").text if review.find_elements(By.XPATH, ".//span[@itemprop='ratingValue']") else ""
                    author_element = review.find_elements(By.XPATH, ".//span[@class='text-gray-800']")
                    if not author_element:
                        author_element = review.find_elements(By.XPATH, ".//span[@class='text-blue-600.cursor-pointer']")
                    author = author_element[0].text if author_element else "Unknown"
                    date = review.find_element(By.XPATH, ".//span[@itemprop='datePublished']").text if review.find_elements(By.XPATH, ".//span[@itemprop='datePublished']") else ""
                    title = review.find_element(By.XPATH, ".//h2").text if review.find_elements(By.XPATH, ".//h2") else ""
                    body = review.find_element(By.XPATH, ".//p[@itemprop='reviewBody']").text if review.find_elements(By.XPATH, ".//p[@itemprop='reviewBody']") else ""

                    review_list.append({
                        'hotelId': row['hotel_id'],
                        'type': 'NORMAL',
                        'status': 'ACTIVE',
                        'score': rating,
                        'authorName': author,
                        'ota': row['ota'],
                        'reviewCreatedAt': date,
                        'content': title + '\n' + body
                    })

                except Exception as e:
                    print(f"âš ï¸ [{idx+1}] ë¦¬ë·° {review_index} ì˜¤ë¥˜: {e}")

        except Exception as e:
            print(f"ðŸš¨ [{idx+1}] í˜¸í…” í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    driver.quit()
    print("ðŸŽ¯ ëª¨ë“  [ì‹ ê·œ í˜¸í…”] í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    return review_list


def crawl_reviews_ikyu_daily(df):
    """
    ê¸°ì¡´ì— ë¦¬ë·°ê°€ ìžˆë˜ í˜¸í…”ë“¤(1ê°œ ì´ìƒ ë³´ìœ )ì— ëŒ€í•œ 'ì¼ìƒ í¬ë¡¤ë§' í•¨ìˆ˜
    """
    review_list = []
    total_hotels = len(df)
    print(f"ðŸ” ì´ {total_hotels}ê°œì˜ [ê¸°ì¡´ í˜¸í…”]ì„ í¬ë¡¤ë§í•©ë‹ˆë‹¤.")

    chrome_options = Options()
    chrome_options.add_experimental_option("detach", True)
    driver = webdriver.Chrome(options=chrome_options)
    time.sleep(3)

    for idx, row in df.iterrows():
        time.sleep(3)
        hotel_link = row['link']
        print(f"\nðŸš€ [{idx+1}/{total_hotels}] í˜¸í…” í¬ë¡¤ë§ ì‹œìž‘: {hotel_link}")

        try:
            driver.get(hotel_link)
            driver.set_window_position(0, 0)
            driver.execute_script("window.scrollTo(0, 500);")

            # ë¦¬ë·° ë²„íŠ¼ í´ë¦­
            try:
                element = WebDriverWait(driver, 5).until(
                    EC.element_to_be_clickable((By.XPATH, "//span[contains(@class, 'text-sm') and contains(@class, 'font-normal') and contains(@class, 'text-blue-700')]"))
                )
            except (NoSuchElementException, TimeoutException):
                try:
                    element = WebDriverWait(driver, 5).until(
                        EC.element_to_be_clickable((By.XPATH, "//button[contains(., 'ã‚¯ãƒã‚³ãƒŸã‚’ã™ã¹ã¦ã¿ã‚‹')]"))
                    )
                except (NoSuchElementException, TimeoutException):
                    print("âŒ ë¦¬ë·° ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìŒ í˜¸í…”ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
                    continue

            driver.execute_script("arguments[0].click();", element)

            # ë¦¬ë·° ëª©ë¡ ë¡œë“œ ëŒ€ê¸°
            try:
                parent_element = WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.CLASS_NAME, "bg-gray-100.px-10.py-16"))
                )
                print(f"âœ… [{idx+1}] ë¦¬ë·° ëª©ë¡ ë¡œë“œë¨!")
            except Exception:
                print(f"âš ï¸ [{idx+1}] ë¦¬ë·° ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ!")
                continue

            # "ç¶šãã‚’ã¿ã‚‹" ë²„íŠ¼ 1~2íšŒ í´ë¦­ (í˜„ìž¬ ì˜ˆì‹œëŠ” ìµœëŒ€ í•œ ë²ˆë§Œ ì‹œë„)
            try:
                next_button = driver.find_element(By.XPATH, "//button[contains(., 'ç¶šãã‚’ã¿ã‚‹')]")
                if next_button.is_displayed() and next_button.is_enabled():
                    next_button.click()
                    time.sleep(2)
                    print("ã€Žç¶šãã‚’ã¿ã‚‹ã€ ë²„íŠ¼ í´ë¦­ ì™„ë£Œ")
            except Exception:
                pass  # ë²„íŠ¼ì´ ì—†ìœ¼ë©´ ë¬´ì‹œ

            # ë¦¬ë·° ì¶”ì¶œ
            review_elements = parent_element.find_elements(By.XPATH, ".//li[section[@itemprop='reviewRating']]")
            print(f"ðŸ“Œ [{idx+1}] ì´ {len(review_elements)}ê°œì˜ ë¦¬ë·°ë¥¼ ì°¾ìŒ!")

            for review_index, review in enumerate(review_elements, start=1):
                try:
                    rating = review.find_element(By.XPATH, ".//span[@itemprop='ratingValue']").text if review.find_elements(By.XPATH, ".//span[@itemprop='ratingValue']") else ""
                    author_element = review.find_elements(By.XPATH, ".//span[@class='text-gray-800']")
                    if not author_element:
                        author_element = review.find_elements(By.XPATH, ".//span[@class='text-blue-600.cursor-pointer']")
                    author = author_element[0].text if author_element else "Unknown"
                    date = review.find_element(By.XPATH, ".//span[@itemprop='datePublished']").text if review.find_elements(By.XPATH, ".//span[@itemprop='datePublished']") else ""
                    title = review.find_element(By.XPATH, ".//h2").text if review.find_elements(By.XPATH, ".//h2") else ""
                    body = review.find_element(By.XPATH, ".//p[@itemprop='reviewBody']").text if review.find_elements(By.XPATH, ".//p[@itemprop='reviewBody']") else ""

                    review_list.append({
                        'hotelId': row['hotel_id'],
                        'type': 'NORMAL',
                        'status': 'ACTIVE',
                        'score': rating,
                        'authorName': author,
                        'ota': row['ota'],
                        'reviewCreatedAt': date,
                        'content': title + '\n' + body
                    })

                except Exception as e:
                    print(f"âš ï¸ [{idx+1}] ë¦¬ë·° {review_index} ì˜¤ë¥˜: {e}")

        except Exception as e:
            print(f"ðŸš¨ [{idx+1}] í˜¸í…” í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    driver.quit()
    print("ðŸŽ¯ ëª¨ë“  [ê¸°ì¡´ í˜¸í…”] í¬ë¡¤ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    return review_list


def after_processing(result):
    """
    (1) 'reviewCreatedAt'ì—ì„œ YYYY/M/D ì¶”ì¶œ & datetime ë³€í™˜
    (2) 'score'ë¥¼ -5~0 ë²”ìœ„ì—ì„œ 0~10 ë²”ìœ„ë¡œ ìŠ¤ì¼€ì¼ë§ (ë‹¨, IKYU ì‹¤ì œ ì ìˆ˜ì²´ê³„ì— ë§žì¶° ì¡°ì • ê°€ëŠ¥)
    (3) uuid ìƒì„±
    """
    result = pd.DataFrame(result)

    # ë‚ ì§œ ì •ê·œì‹ ì¶”ì¶œ -> datetime ë³€í™˜
    def extract_date(x):
        match = re.search(r'(\d{4}/\d{1,2}/\d{1,2})', x)
        if match:
            return match.group(1)
        return x

    result['reviewCreatedAt'] = result['reviewCreatedAt'].apply(extract_date)
    result['reviewCreatedAt'] = pd.to_datetime(result['reviewCreatedAt'], format='%Y/%m/%d', errors='coerce')

    # í‰ì  ë³€í™˜ (ì˜ˆ: 0~5 â†’ 0 ~ 10 ë²”ìœ„)
    result['score'] = pd.to_numeric(result['score'], errors='coerce')
    if not result['score'].isna().all():
        old_min = result['score'].min()
        old_max = result['score'].max()
        diff = old_max - old_min
        if diff != 0:
            result['score'] = ((result['score'] - old_min) / diff) * 10
            result['score'] = result['score'].round(1)
        else:
            # ë™ì¼ ì ìˆ˜ë§Œ ìžˆëŠ” ê²½ìš°
            result['score'] = 5.0  # ìž„ì˜ì˜ ì¤‘ì•™ê°’ ë¶€ì—¬

    # UUID
    result['uuid'] = [str(uuid.uuid4()) for _ in range(len(result))]

    return result


def filter_new_reviews_ikyu_by_date(daily_df, latest_df):
    """
    latest_dfì— 'hotelId'ë³„ ë§ˆì§€ë§‰(reviewCreatedAtê°€ ê°€ìž¥ ëŠ¦ì€) ë‚ ì§œê°€ ìžˆë‹¤ê³  ê°€ì •í•˜ê³ ,
    daily_dfì—ì„œ ê·¸ ë‚ ì§œë³´ë‹¤ ë” ë‚˜ì¤‘(>)ì— ìž‘ì„±ëœ ë¦¬ë·°ë“¤ë§Œ í•„í„°ë§í•´ì„œ ë°˜í™˜.
    """

    if daily_df.empty:
        return daily_df

    # í˜¹ì‹œ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë“¤ì–´ì˜¬ ìˆ˜ë„ ìžˆìœ¼ë¯€ë¡œ
    daily_df = pd.DataFrame(daily_df).copy()
    latest_df = pd.DataFrame(latest_df).copy()


    # hotelIdê°€ ì—†ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if 'hotelId' not in daily_df.columns:
        return daily_df

    # ë‚ ì§œí˜• ë³€í™˜
    daily_df['reviewCreatedAt'] = pd.to_datetime(daily_df['reviewCreatedAt'], errors='coerce')
    latest_df['reviewCreatedAt'] = pd.to_datetime(latest_df['reviewCreatedAt'], errors='coerce')

    # latest_dfë¥¼ hotelId -> ë§ˆì§€ë§‰ ë‚ ì§œ ë¡œ ë§µí•‘
    # (ì‹¤ì œë¡œëŠ” ì—¬ëŸ¬ ë¦¬ë·° ì¤‘ "ê°€ìž¥ ìµœì‹  ë‚ ì§œ"ê°€ ì €ìž¥ë˜ì–´ ìžˆë‹¤ê³  ê°€ì •)
    last_known_dict = {}
    for row in latest_df.itertuples():
        last_known_dict[row.hotelId] = pd.to_datetime(row.reviewCreatedAt)

    # hotelId ë³„ í•„í„°ë§
    filtered_rows = []
    for hotel_id, group in daily_df.groupby('hotelId', sort=False):
        group = group.copy()

        # ë§Œì•½ latest_dfì— ì—†ìœ¼ë©´ => ì „ë¶€ ì‹ ê·œ ì·¨ê¸‰
        if hotel_id not in last_known_dict:
            filtered_rows.append(group)
            continue

        last_date = last_known_dict[hotel_id]
        # last_dateë³´ë‹¤ ë‚˜ì¤‘(>)ì¸ ê²ƒë§Œ í•„í„°
        new_reviews = group[group['reviewCreatedAt'] > last_date]
        filtered_rows.append(new_reviews)

    result_df = pd.concat(filtered_rows, ignore_index=True)
    return result_df

